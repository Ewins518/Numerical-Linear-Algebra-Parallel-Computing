{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPK+ETaAHBIDt/GmqokqEJq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ewins518/Numerical-Linear-Algebra-Parallel-Computing/blob/main/week1/assignments/complexity_assignement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg.blas import dgemv, ddot, dnrm2\n"
      ],
      "metadata": {
        "id": "psdKa3gx3_Ai"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n"
      ],
      "metadata": {
        "id": "jqb_NUSl18pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   The first solution counts the number of divisors of an integer n as input. We've a variable d initialized to 1 and a counter variable initialized to 0. Once within a while loop, it stays there as long as d is smaller or equal to n. Using the modulo operator %, the function determines whether n is divisible by d inside the loop. If the outcome is zero, the count is increased by one. The loop then moves on to the next iteration after incrementing d by 1. The function returns the final result of count once the loop has finished.\n",
        "\n",
        "2. The solution 2 is an optimized algorithm to count the divisors by iterating only up to the square root of n. If a divisor d is found, the function increments the counter count by 1 if d is a perfect square divisor, or by 2 if d is not a perfect square divisor (in this case, both d and n/d are divisors). Finally, the function returns the total count of divisors.\n",
        "\n"
      ],
      "metadata": {
        "id": "dlB817QO2UMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QJrjFoM71GoH"
      },
      "outputs": [],
      "source": [
        "def count_divisors_1(n):\n",
        "    count=0\n",
        "    d=1\n",
        "    while d<=n:\n",
        "        if n%d==0:\n",
        "            count +=1\n",
        "        d+=1\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_divisors_2(n):\n",
        "    count=0\n",
        "    d=1\n",
        "    while d*d<=n:\n",
        "        if n%d==0:\n",
        "            count +=1 if n/d==d else 2\n",
        "        d+=1\n",
        "    return count"
      ],
      "metadata": {
        "id": "prbW4cF535kY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "n_values = [10, 100, 10000000]\n",
        "\n",
        "for n in n_values:\n",
        "    print(f\"Testing for n = {n}\")\n",
        "    \n",
        "    # Test count_divisors_so1\n",
        "    start_time = time.time()\n",
        "    count_divisors_1(n)\n",
        "    end_time = time.time()\n",
        "    print(f\"count_divisors_1 : {end_time - start_time:.6f} seconds.\")\n",
        "    \n",
        "    # Test count_divisors_so2\n",
        "    start_time = time.time()\n",
        "    count_divisors_2(n)\n",
        "    end_time = time.time()\n",
        "    print(f\"count_divisors_2 : {end_time - start_time:.6f} seconds.\")\n",
        "    \n",
        "    print(\"***************************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LWbwUxm36rV",
        "outputId": "ca4e9894-8f8b-4532-813d-76839e244a5c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for n = 10\n",
            "count_divisors_1 : 0.000005 seconds.\n",
            "count_divisors_2 : 0.000005 seconds.\n",
            "***************************************\n",
            "Testing for n = 100\n",
            "count_divisors_1 : 0.000024 seconds.\n",
            "count_divisors_2 : 0.000005 seconds.\n",
            "***************************************\n",
            "Testing for n = 10000000\n",
            "count_divisors_1 : 1.181183 seconds.\n",
            "count_divisors_2 : 0.000482 seconds.\n",
            "***************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The faster algorithm is the second one"
      ],
      "metadata": {
        "id": "9jXxdbXh4RdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_divisors_1(n):\n",
        "    count = 0\n",
        "    d = 1\n",
        "    ops = 0\n",
        "    while d <= n:\n",
        "        if n % d == 0:\n",
        "            count += 1\n",
        "            ops += 1\n",
        "        d += 1\n",
        "        ops += 2 # addition and comparison\n",
        "    return count, ops\n",
        "\n",
        "def count_divisors_2(n):\n",
        "    count = 0\n",
        "    d = 1\n",
        "    ops = 0\n",
        "    while d * d <= n:\n",
        "        if n % d == 0:\n",
        "            count += 1\n",
        "            if n / d == d:\n",
        "                ops += 2 # division and comparison\n",
        "            else:\n",
        "                count += 1\n",
        "                ops += 3 # division, addition and comparison\n",
        "        d += 1\n",
        "        ops += 3 # multiplication, addition and comparison\n",
        "    return count, ops\n",
        "\n",
        "n_values = [10, 1000, 10000000]\n",
        "\n",
        "for n in n_values:\n",
        "    print(f\"Testing for n = {n}\")\n",
        "    \n",
        "    # Test count_divisors_1\n",
        "    count_1, ops_1 = count_divisors_1(n)\n",
        "    print(f\"count_divisors_1 returned {count_1} and executed {ops_1} operations.\")\n",
        "    \n",
        "    # Test count_divisors_2\n",
        "    count_2, ops_2 = count_divisors_2(n)\n",
        "    print(f\"count_divisors_2 returned {count_2} and executed {ops_2} operations.\")\n",
        "    \n",
        "    print(\"------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6igmebG54OFz",
        "outputId": "4d4873d2-99ae-4990-c636-804074044bd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for n = 10\n",
            "count_divisors_1 returned 4 and executed 24 operations.\n",
            "count_divisors_2 returned 4 and executed 15 operations.\n",
            "------------------------\n",
            "Testing for n = 1000\n",
            "count_divisors_1 returned 16 and executed 2016 operations.\n",
            "count_divisors_2 returned 16 and executed 117 operations.\n",
            "------------------------\n",
            "Testing for n = 10000000\n",
            "count_divisors_1 returned 64 and executed 20000064 operations.\n",
            "count_divisors_2 returned 64 and executed 9582 operations.\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Big-O notation"
      ],
      "metadata": {
        "id": "EE45te-x64fT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Proof of T(n) = $\\mathcal{O}(n^3)$\n",
        "$T(n) = 3n^3 + 2n^2 + \\frac{1}{2}n + 7 \\le 3n^3 + 2n^3 + \\frac{1}{2}n^3 + 7n^3 = 13.5 n^3$\n",
        "We can now choose c = 13.5 and $n_0 = 1$ Then for all $n \\ge 1$ we obtain $T(n) \\le 3n^3 $\n",
        "This demonstrates that ð‘‡(ð‘›) is $\\mathcal{O}(n^3)$ since we have found constants c and $n_0$ that satisfy the definition of Big-O notation"
      ],
      "metadata": {
        "id": "jjgBzAJ17A7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proof of $âˆ€ k \\ge 1, n^k$ is not $\\mathcal{O}(n^{k-1})$\n",
        "In order to demonstrate that, we will employ proof by contradiction. Let us assume that there are constants c and $n_0$ such that $n^{k-1} â‰¤ cn^{k-1}$ for all $n \\ge n_0$.  To simplify this inequality, we can divide both sides by $n^{k-1}$(since $n^{k-1} \\ne 0$). This yields the inequality $n \\le c$ for all $n \\ge n_0$. However, this contradicts the fact that c is a constant, as n can be made arbitrarily large. Thus, our initial assumption that $n^{k-1} â‰¤ cn^{k-1}$ is  must be false. Consequently, we have established that $âˆ€ k \\ge 1, n^k$ is not $\\mathcal{O}(n^{k-1})$."
      ],
      "metadata": {
        "id": "XekyPReE89f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge sort"
      ],
      "metadata": {
        "id": "fOLaNhL--sh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(A, B):\n",
        "    c = np.empty(len(A) + len(B), dtype=A.dtype)\n",
        "    i = j = k = 0\n",
        "    while i < len(A) and j < len(B):\n",
        "        if A[i] <= B[j]:\n",
        "            c[k] = A[i]\n",
        "            i += 1\n",
        "        else:\n",
        "            c[k] = B[j]\n",
        "            j += 1\n",
        "        k += 1\n",
        "    while i < len(A):\n",
        "        c[k] = A[i]\n",
        "        i += 1\n",
        "        k += 1\n",
        "    while j < len(B):\n",
        "        c[k] = B[j]\n",
        "        j += 1\n",
        "        k += 1\n",
        "    return c"
      ],
      "metadata": {
        "id": "memOJp0r44vu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "A = np.array([2,5,8,17,19])\n",
        "B = np.array([1,4,5,7,11,14])"
      ],
      "metadata": {
        "id": "hYAdDfI2-6_r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge(A,B)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWrtMSrR-9qi",
        "outputId": "fcf2a00e-065b-4165-de6e-58e42d837da3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  4,  5,  5,  7,  8, 11, 14, 17, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the divide-and-conquer approach, the time complexity of the optimized merge function is $\\mathcal{O}(mlog(m+n))$, where m and n denote the lengths of the input arrays A and B, respectively.\n",
        "\n",
        "This is due to the fact that the function divides the input arrays recursively into halves until it reaches the base case of arrays with 0 or 1 length. Afterward, it merges the subarrays in a bottom-up approach. The number of recursive calls is proportional to the height of the recursive call tree, which is $log(m+n)$\n",
        " for two arrays with lengths m and n. In each recursive call, two subarrays with a total length of m+n are compared and merged, which takes O(m+n) time. Thus, the total time complexity of the function is $\\mathcal{O}((m+n)log(m+n))$. If both arrays have the same length and all elements in one array are greater than all elements in the other array, the function would require $log(m+n)$ recursive calls. In each recursive call, the function would merge two subarrays of size $\\frac{m}{2}$ and $\\frac{n}{2}$  Thus, in the worst case, the total time complexity of the function is $\\mathcal{O}(mlog(m+n))$ or $\\mathcal{O}(mlog(m+n))$\n",
        ", whichever is larger."
      ],
      "metadata": {
        "id": "dsdw3SAqASWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The master method\n"
      ],
      "metadata": {
        "id": "YlwvNo1yCTxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  The master method is a technique that can be used to analyze the time complexity of divide-and-conquer algorithms, such as merge sort and binary search. To apply the master method, we need to represent the time complexity of the algorithm in the following form: $T(n) = aT(\\frac{n}{b}) + f(n)$, where T(n) is the time complexity of the algorithm, a is the number of subproblems, $\\frac{n}{b}$ is the size of each subproblem, and f(n) is the time complexity of dividing the problem and combining the solutions.\n",
        "\n",
        "For merge sort, we divide the input array into two halves of equal size, recursively sort each half, and then merge the sorted halves using the merge function with $\\mathcal{O}(n)$ time complexity. Thus, the time complexity of merge sort can be represented as $T(n) = 2T(\\frac{n}{2}) + \\mathcal{O}(n)$\n",
        "\n",
        "According to the master method, there are three possible cases for the time complexity of the algorithm based on the value of f(n):\n",
        "\n",
        "\n",
        "1.   if $f(n) = \\mathcal{O}(n^c)$  for some constant $c < log_b(a)$ then $T(n) = \\mathcal{O}(n^c)$\n",
        "2.   if $f(n) = \\mathcal{O}(n^clog(n))$  for some constant $c = log_b(a)$ then $T(n) = \\mathcal{O}(n^clog(n))$\n",
        "3.   if $f(n) = \\mathcal{O}(n^c)$  for some constant $c > log_b(a)$ then $T(n) = \\mathcal{O}(n^c)$\n",
        "\n",
        "For merge sort, we've $a=2, b=2$ and $f(n) = \\mathcal{O}(n)$. Therefore, $ c = log_2(2) = 1$ and we are in case 2 of the master method. Thus, the time complexity of merge sort  is  $\\mathcal{O}(nlog(n))$\n",
        "\n",
        "*  On the other hand, binary search is a divide-and-conquer algorithm for searching a sorted array by repeatedly dividing the search interval in half. Its time complexity can be represented as $T(n) = T(\\frac{n}{2}) + \\mathcal{O}(1)$.  In this case,, a=1, b=2 and $f(n) = \\mathcal{O}(1)$. Thus, $ c = log_2(1) = 0$ and we are in case 1 of the master methodTherefore, the time complexity of binary search is $\\mathcal{O}(log(n))$\n",
        ".\n",
        "\n",
        "In summary, the master method provides a convenient way to determine the time complexity of divide-and-conquer algorithms, and it can be used to show that the time complexity of merge sort is $\\mathcal{O}(nlog(n))$\n",
        " and that the time complexity of binary search is $\\mathcal{O}(log(n))$\n",
        ".\n",
        "\n"
      ],
      "metadata": {
        "id": "46pRWLV7CcJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus"
      ],
      "metadata": {
        "id": "9swkA5rqJLeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_sort(A, B):\n",
        "    # Check if one or both arrays are empty\n",
        "    if not A:\n",
        "        return B\n",
        "    elif not B:\n",
        "        return A\n",
        "    \n",
        "    # Divide the input arrays into two halves\n",
        "    mid_a = len(A) // 2\n",
        "    mid_b = len(B) // 2\n",
        "    \n",
        "    # Recursively sort the left and right halves of each array\n",
        "    left_a = merge_sort(A[:mid_a], B[:mid_b])\n",
        "    right_a = merge_sort(A[mid_a:], B[mid_b:])\n",
        "    \n",
        "    # Merge the sorted halves of the arrays\n",
        "    return merge(left_a, right_a)\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "    # Compare and merge the elements from both arrays\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] <= right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "    # Append any remaining elements in the left or right array\n",
        "    result += left[i:]\n",
        "    result += right[j:]\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "PF8mLaiYJNch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine the time complexity of merge sort, we can use a recursion tree. At each level of the tree, the size of the input arrays is halved. The number of levels in the tree is given by $log_2(n)$\n",
        ", where \n",
        "  n is the size of the input."
      ],
      "metadata": {
        "id": "IfGlAuYmJ_fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the complexity of the quicksort algorithm:\n",
        "\n",
        "Quicksort is an algorithm based on the divide-and-conquer technique. It involves selecting a pivot element from the given array and dividing the remaining elements into two sub-arrays, based on whether they are smaller or larger than the pivot. These sub-arrays are then sorted recursively using quicksort. The overall steps for quicksort include selecting the pivot, partitioning the array, and recursively sorting the sub-arrays.\n",
        "\n",
        "The worst-case time complexity of quicksort is $\\mathcal{O}(n^2)$\n",
        ", which happens when the pivot is consistently the smallest or largest element in the array. On the other hand, the average and best-case time complexities of quicksort are $\\mathcal{O}(nlog(n))$\n",
        ". The time complexity of quicksort can be broken down into three parts, including partitioning the array, the best-case scenario, and the worst-case scenario.\n",
        "\n",
        "Partitioning the array requires $\\mathcal{O}(n)$\n",
        " time in the worst case. The best-case scenario occurs when the pivot divides the array into two sub-arrays of roughly equal size, resulting in a recursion depth of $\\mathcal{O}(log(n))$\n",
        " and a time complexity of $\\mathcal{O}(nlog(n)$\n",
        ". In contrast, the worst-case scenario arises when the pivot is always the smallest or largest element in the array, resulting in a recursion depth of n and a time complexity of $\\mathcal{O}(n^2)$\n",
        "\n",
        "In summary, quicksort has an average and best-case time complexity of $\\mathcal{O}(nlog (n))$\n",
        " and a worst-case time complexity of \n",
        "$\\mathcal{O}(n^2)$. Quicksort is known for its superior performance over other sorting algorithms due to its cache efficiency and low memory requirements."
      ],
      "metadata": {
        "id": "0_QfCfviKS6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix multiplication"
      ],
      "metadata": {
        "id": "8VHEBGu7LBAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_multiply(A, B):\n",
        "    # Get the number of rows and columns of matrices A and B\n",
        "    m, p = len(A), len(B)\n",
        "    n, q = len(B[0]), len(A[0])\n",
        "\n",
        "    # Check if the matrices have compatible dimensions\n",
        "    if p != n:\n",
        "        raise ValueError(\"Matrices have incompatible dimensions\")\n",
        "\n",
        "    # Initialize the product matrix with zeros\n",
        "    C = [[0 for j in range(q)] for i in range(m)]\n",
        "    \n",
        "    # Compute the dot product for each row of A and each column of B\n",
        "    for i in range(m):\n",
        "        for j in range(q):\n",
        "            for k in range(p):\n",
        "                C[i][j] += A[i][k] * B[k][j]\n",
        "    \n",
        "    return C"
      ],
      "metadata": {
        "id": "LNXPxSUxJ0Hx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Analyzing the complexity of the previous algorithm using big-O notation:\n",
        "\n",
        "The matrix multiplication algorithm has a time complexity of $\\mathcal{O}(n^3)$\n",
        " due to the presence of three nested loops over matrices of size n. The reason behind this is that for each element in the resulting matrix, we need to perform n multiplications and n additions. Thus, the total number of operations increases in proportion to $n^3$\n",
        ", resulting in a cubic time complexity"
      ],
      "metadata": {
        "id": "Pmu6XlEjLHr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#include <stdio.h>\n",
        "\n",
        "#define ROW_A 3\n",
        "#define COL_A 2\n",
        "#define ROW_B 2\n",
        "#define COL_B 3\n",
        "\n",
        "void matrix_multiply(int A[][COL_A], int B[][COL_B], int C[][COL_B]) {\n",
        "    for (int i = 0; i < ROW_A; ++i) {\n",
        "        for (int j = 0; j < COL_B; ++j) {\n",
        "            C[i][j] = 0;\n",
        "            for (int k = 0; k < COL_A; ++k) {\n",
        "                C[i][j] += A[i][k] * B[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_matrix(int matrix[][COL_B], int row, int col) {\n",
        "    for (int i = 0; i < row; ++i) {\n",
        "        for (int j = 0; j < col; ++j) {\n",
        "            printf(\"%d \", matrix[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int A[ROW_A][COL_A] = {{1, 2}, {3, 4}, {5, 6}};\n",
        "    int B[ROW_B][COL_B] = {{1, 2, 3}, {4, 5, 6}};\n",
        "    int C[ROW_A][COL_B];\n",
        "\n",
        "    matrix_multiply(A, B, C);\n",
        "\n",
        "    print_matrix(C, ROW_A, COL_B);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "5BoXXH8eLFFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Optimization of the function of multiplication provided in the previous answer:\n",
        "\n",
        "The original matrix multiplication algorithm has a time complexity of $O(n^3)$. To improve the efficiency of the algorithm, a technique called \"loop unrolling\" can be utilized. This technique involves processing multiple elements in a single iteration, which reduces the number of loop iterations required and results in faster execution.\n",
        "\n",
        "The number of elements processed in each iteration is known as the \"unroll factor\". By increasing the unroll factor, the overhead of the loop can be further reduced, resulting in even faster execution times."
      ],
      "metadata": {
        "id": "8RTZCEzVLcnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   A\n",
        "2.   D\n",
        "3.   C\n",
        "\n"
      ],
      "metadata": {
        "id": "AMfcA_mKLlj5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmTG9o63LkUw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}